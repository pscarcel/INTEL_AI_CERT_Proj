{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Data visualisation\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision.models import *\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "NUMBER_EPOCHS=100\n",
    "IMG_SIZE=100\n",
    "\n",
    "def imshow(img,text=None,should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train pairs: 3066\n",
      "Total val pairs: 296\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_famillies = \"F09\"\n",
    "all_images = glob(os.getcwd() +\"/input/train/*/*/*.jpg\")\n",
    "all_images = [path.replace(\"\\\\\", \"/\") for path in all_images]\n",
    "ppl = [x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2] for x in all_images]\n",
    "relationships = pd.read_csv(os.getcwd() + \"/input/train_relationships.csv\")\n",
    "relationships = list(zip(relationships.p1.values, relationships.p2.values))\n",
    "relationships = [x for x in relationships if x[0] in ppl and x[1] in ppl]\n",
    "\n",
    "train = [x for x in relationships if val_famillies not in x[0]]\n",
    "val = [x for x in relationships if val_famillies in x[0]]\n",
    "\n",
    "print(\"Total train pairs:\", len(train))    \n",
    "print(\"Total val pairs:\", len(val))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainingDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,imageFolderDataset, relationships, transform=None):\n",
    "        self.imageFolderDataset = imageFolderDataset    \n",
    "        self.relationships = relationships #choose either train or val dataset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img0_info = self.relationships[index][0]\n",
    "        img0_path = glob(os.getcwd() +\"/input/train/\"+img0_info+\"/*.jpg\")\n",
    "        img0_path = [path.replace(\"\\\\\", \"/\") for path in img0_path]\n",
    "        img0_path = random.choice(img0_path)\n",
    "        \n",
    "        cand_relationships = [x for x in self.relationships if x[0]==img0_info or x[1]==img0_info]\n",
    "        if cand_relationships==[]:\n",
    "            should_get_same_class = 0\n",
    "        else:\n",
    "            should_get_same_class = random.randint(0,1) \n",
    "\n",
    "        if should_get_same_class==1:\n",
    "            img1_info = random.choice(cand_relationships)\n",
    "            if img1_info[0]!=img0_info:\n",
    "                img1_info=img1_info[0]\n",
    "            else:\n",
    "                img1_info=img1_info[1]\n",
    "            img1_path = glob(os.getcwd() + \"/input/train/\"+img1_info+\"/*.jpg\")#randomly choose a img of this person\n",
    "            img1_path = random.choice(img1_path)\n",
    "        else:#0 means non-related\n",
    "            randChoose = True#in case the chosen person is related to first person\n",
    "            while randChoose:\n",
    "                img1_path = random.choice(self.imageFolderDataset.imgs)[0]\n",
    "                img1_info = img1_path.split(\"/\")[-3] + \"/\" + img1_path.split(\"/\")[-2]\n",
    "                randChoose = False\n",
    "                for x in cand_relationships:#if so, randomly choose another person\n",
    "                    if x[0]==img1_info or x[1]==img1_info:\n",
    "                        randChoose = True\n",
    "                        break\n",
    "                    \n",
    "        img0 = Image.open(img0_path)\n",
    "        img1 = Image.open(img1_path)\n",
    "        \n",
    "        if self.transform is not None:#\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        \n",
    "        return img0, img1 , should_get_same_class\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eerieKNIGHT\\AppData\\Local\\Temp\\ipykernel_34132\\2136763999.py:12: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "folder_dataset = dset.ImageFolder(root=os.getcwd() +\"/input/train\")\n",
    "\n",
    "trainset = trainingDataset(imageFolderDataset=folder_dataset,\n",
    "                                        relationships=train,\n",
    "                                        transform=transforms.Compose([transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ]))\n",
    "trainloader = DataLoader(trainset,\n",
    "                        shuffle=True,#whether randomly shuffle data in each epoch, but cannot let data in one batch in order.\n",
    "                        batch_size=BATCH_SIZE)\n",
    "valset = trainingDataset(imageFolderDataset=folder_dataset,\n",
    "                                        relationships=val,\n",
    "                                        transform=transforms.Compose([transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ]))\n",
    "valloader = DataLoader(valset,\n",
    "                        shuffle=True,\n",
    "                        batch_size=BATCH_SIZE)\n",
    "\n",
    "vis_dataloader = DataLoader(trainset,\n",
    "                        shuffle=True,\n",
    "                        batch_size=8)\n",
    "dataiter = iter(vis_dataloader)\n",
    "\n",
    "\n",
    "example_batch = next(dataiter)\n",
    "concatenated = torch.cat((example_batch[0],example_batch[1]),0)\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n",
    "print(example_batch[2].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):# A simple implementation of siamese network, ResNet50 is used\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(3, 64, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout2d(p=.2),\n",
    "            \n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(64, 64, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout2d(p=.2),\n",
    "\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(64, 32, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout2d(p=.2),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(2*32*100*100, 500)\n",
    "        self.fc2 = nn.Linear(500, 500)\n",
    "        self.fc3 = nn.Linear(500, 2)\n",
    "\n",
    "\n",
    "    def forward(self, input1, input2)\n",
    "        output1 = self.cnn1(input1)\n",
    "        output1 = output1.view(output1.size()[0], -1)#make it suitable for fc layer.\n",
    "        output2 = self.cnn1(input2)\n",
    "        output2 = output2.view(output2.size()[0], -1)\n",
    "        \n",
    "        output = torch.cat((output1, output2),1)\n",
    "        output = F.relu(self.fc1(output))\n",
    "        output = F.relu(self.fc2(output))\n",
    "        output = self.fc3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch： 0  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 56 %\n",
      "Epoch： 1  start.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eerieKNIGHT\\AppData\\Local\\Temp\\ipykernel_34132\\2136763999.py:16: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 296 val pairs in F09 : 59 %\n",
      "Epoch： 2  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 54 %\n",
      "Epoch： 3  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 63 %\n",
      "Epoch： 4  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 57 %\n",
      "Epoch： 5  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 61 %\n",
      "Epoch： 6  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 57 %\n",
      "Epoch： 7  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 57 %\n",
      "Epoch： 8  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 61 %\n",
      "Epoch： 9  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 63 %\n",
      "Epoch： 10  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 64 %\n",
      "Epoch： 11  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 55 %\n",
      "Epoch： 12  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 57 %\n",
      "Epoch： 13  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 62 %\n",
      "Epoch： 14  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 61 %\n",
      "Epoch： 15  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 62 %\n",
      "Epoch： 16  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 60 %\n",
      "Epoch： 17  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 60 %\n",
      "Epoch： 18  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 59 %\n",
      "Epoch： 19  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 63 %\n",
      "Epoch： 20  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 55 %\n",
      "Epoch： 21  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 55 %\n",
      "Epoch： 22  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 57 %\n",
      "Epoch： 23  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 53 %\n",
      "Epoch： 24  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 60 %\n",
      "Epoch： 25  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 57 %\n",
      "Epoch： 26  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 58 %\n",
      "Epoch： 27  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 62 %\n",
      "Epoch： 28  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 65 %\n",
      "Epoch： 29  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 66 %\n",
      "Epoch： 30  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 62 %\n",
      "Epoch： 31  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 64 %\n",
      "Epoch： 32  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 65 %\n",
      "Epoch： 33  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 59 %\n",
      "Epoch： 34  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 61 %\n",
      "Epoch： 35  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 55 %\n",
      "Epoch： 36  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 60 %\n",
      "Epoch： 37  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 60 %\n",
      "Epoch： 38  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 61 %\n",
      "Epoch： 39  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 54 %\n",
      "Epoch： 40  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 56 %\n",
      "Epoch： 41  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 60 %\n",
      "Epoch： 42  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 59 %\n",
      "Epoch： 43  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 59 %\n",
      "Epoch： 44  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 59 %\n",
      "Epoch： 45  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 59 %\n",
      "Epoch： 46  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 58 %\n",
      "Epoch： 47  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 56 %\n",
      "Epoch： 48  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 60 %\n",
      "Epoch： 49  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 55 %\n",
      "Epoch： 50  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 61 %\n",
      "Epoch： 51  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 51 %\n",
      "Epoch： 52  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 58 %\n",
      "Epoch： 53  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 57 %\n",
      "Epoch： 54  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 59 %\n",
      "Epoch： 55  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 61 %\n",
      "Epoch： 56  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 60 %\n",
      "Epoch： 57  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 58 %\n",
      "Epoch： 58  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 55 %\n",
      "Epoch： 59  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 57 %\n",
      "Epoch： 60  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 61 %\n",
      "Epoch： 61  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 58 %\n",
      "Epoch： 62  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 57 %\n",
      "Epoch： 63  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 60 %\n",
      "Epoch： 64  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 56 %\n",
      "Epoch： 65  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 60 %\n",
      "Epoch： 66  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 58 %\n",
      "Epoch： 67  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 63 %\n",
      "Epoch： 68  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 58 %\n",
      "Epoch： 69  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 55 %\n",
      "Epoch： 70  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 57 %\n",
      "Epoch： 71  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 61 %\n",
      "Epoch： 72  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 55 %\n",
      "Epoch： 73  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 55 %\n",
      "Epoch： 74  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 57 %\n",
      "Epoch： 75  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 62 %\n",
      "Epoch： 76  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 56 %\n",
      "Epoch： 77  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 56 %\n",
      "Epoch： 78  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 63 %\n",
      "Epoch： 79  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 53 %\n",
      "Epoch： 80  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 53 %\n",
      "Epoch： 81  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 60 %\n",
      "Epoch： 82  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 56 %\n",
      "Epoch： 83  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 58 %\n",
      "Epoch： 84  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 55 %\n",
      "Epoch： 85  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 52 %\n",
      "Epoch： 86  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 53 %\n",
      "Epoch： 87  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 53 %\n",
      "Epoch： 88  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 56 %\n",
      "Epoch： 89  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 55 %\n",
      "Epoch： 90  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 51 %\n",
      "Epoch： 91  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 56 %\n",
      "Epoch： 92  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 53 %\n",
      "Epoch： 93  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 55 %\n",
      "Epoch： 94  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 55 %\n",
      "Epoch： 95  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 52 %\n",
      "Epoch： 96  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 53 %\n",
      "Epoch： 97  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 57 %\n",
      "Epoch： 98  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 52 %\n",
      "Epoch： 99  start.\n",
      "Accuracy of the network on the 296 val pairs in F09 : 55 %\n"
     ]
    }
   ],
   "source": [
    "net = SiameseNetwork().cuda()\n",
    "criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number= 0\n",
    "\n",
    "for epoch in range(0,NUMBER_EPOCHS):\n",
    "    print(\"Epoch：\", epoch, \" start.\")\n",
    "    for i, data in enumerate(trainloader,0):\n",
    "        img0, img1 , labels = data \n",
    "        img0, img1 , labels = img0.cuda(), img1.cuda() , labels.cuda()#move to GPU\n",
    "        optimizer.zero_grad()#clear the calculated grad in previous batch\n",
    "        outputs = net(img0,img1)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i %10 == 0 :#show changes of loss value after each 10 batches\n",
    "            iteration_number +=10\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss.item())\n",
    "    \n",
    "    #test the network after finish each epoch\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            img0, img1 , labels = data\n",
    "            img0, img1 , labels = img0.cuda(), img1.cuda() , labels.cuda()\n",
    "            outputs = net(img0,img1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            \n",
    "    print('Accuracy of the network on the', total_val, 'val pairs in',val_famillies, ': %d %%' % (100 * correct_val / total_val))\n",
    "    show_plot(counter,loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,transform=None):\n",
    "        self.test_df = pd.read_csv(os.getcwd() + '/input/sample_submission.csv')\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        #data in submission.csv:\n",
    "        #       img_pair               is_related\n",
    "        #face05508.jpg-face01210.jpg       0\n",
    "        #face05820.jpg-face03938.jpg       0\n",
    "        \n",
    "        img0_path = self.test_df.iloc[index].img_pair.split(\"-\")[0]\n",
    "        img1_path = self.test_df.iloc[index].img_pair.split(\"-\")[1]\n",
    "        \n",
    "        img0 = Image.open(os.getcwd() + '/input/test/'+img0_path)\n",
    "        img1 = Image.open(os.getcwd() + '/input/test/'+img1_path)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        \n",
    "        return img0, img1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = testDataset(transform=transforms.Compose([transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ]))\n",
    "testloader = DataLoader(testset,\n",
    "                        shuffle=False,\n",
    "                        batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_pair</th>\n",
       "      <th>is_related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>face05508.jpg-face01210.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>face05750.jpg-face00898.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>face05820.jpg-face03938.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>face02104.jpg-face01172.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>face02428.jpg-face05611.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>face01219.jpg-face00274.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>face04262.jpg-face00555.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>face03697.jpg-face01892.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>face03524.jpg-face00319.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>face03410.jpg-face05368.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>face00292.jpg-face06004.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>face00353.jpg-face01203.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>face03140.jpg-face05223.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>face02915.jpg-face03312.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>face03012.jpg-face04103.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>face02240.jpg-face02336.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>face02131.jpg-face05209.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>face04105.jpg-face01209.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>face03565.jpg-face02509.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>face02836.jpg-face01540.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>face02832.jpg-face05386.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>face02596.jpg-face02913.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>face02231.jpg-face05835.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>face00451.jpg-face03664.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>face01644.jpg-face01682.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>face03988.jpg-face03379.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>face00908.jpg-face05944.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>face05117.jpg-face03498.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>face05466.jpg-face02942.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>face01537.jpg-face00187.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>face03609.jpg-face05219.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>face04820.jpg-face04526.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>face05963.jpg-face00176.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>face04372.jpg-face03101.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>face01496.jpg-face04980.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>face04215.jpg-face01123.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>face02624.jpg-face05000.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>face04434.jpg-face03376.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>face03417.jpg-face03461.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>face03142.jpg-face00593.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>face00094.jpg-face04094.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>face05700.jpg-face03910.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>face03620.jpg-face03203.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>face05074.jpg-face03806.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>face03836.jpg-face05917.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>face04495.jpg-face02846.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>face01690.jpg-face01033.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>face01766.jpg-face06057.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>face04896.jpg-face01845.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>face05468.jpg-face04688.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       img_pair  is_related\n",
       "0   face05508.jpg-face01210.jpg         1.0\n",
       "1   face05750.jpg-face00898.jpg         1.0\n",
       "2   face05820.jpg-face03938.jpg         1.0\n",
       "3   face02104.jpg-face01172.jpg         0.0\n",
       "4   face02428.jpg-face05611.jpg         0.0\n",
       "5   face01219.jpg-face00274.jpg         0.0\n",
       "6   face04262.jpg-face00555.jpg         0.0\n",
       "7   face03697.jpg-face01892.jpg         0.0\n",
       "8   face03524.jpg-face00319.jpg         1.0\n",
       "9   face03410.jpg-face05368.jpg         0.0\n",
       "10  face00292.jpg-face06004.jpg         0.0\n",
       "11  face00353.jpg-face01203.jpg         0.0\n",
       "12  face03140.jpg-face05223.jpg         0.0\n",
       "13  face02915.jpg-face03312.jpg         0.0\n",
       "14  face03012.jpg-face04103.jpg         0.0\n",
       "15  face02240.jpg-face02336.jpg         1.0\n",
       "16  face02131.jpg-face05209.jpg         1.0\n",
       "17  face04105.jpg-face01209.jpg         1.0\n",
       "18  face03565.jpg-face02509.jpg         1.0\n",
       "19  face02836.jpg-face01540.jpg         0.0\n",
       "20  face02832.jpg-face05386.jpg         0.0\n",
       "21  face02596.jpg-face02913.jpg         0.0\n",
       "22  face02231.jpg-face05835.jpg         0.0\n",
       "23  face00451.jpg-face03664.jpg         0.0\n",
       "24  face01644.jpg-face01682.jpg         0.0\n",
       "25  face03988.jpg-face03379.jpg         1.0\n",
       "26  face00908.jpg-face05944.jpg         0.0\n",
       "27  face05117.jpg-face03498.jpg         1.0\n",
       "28  face05466.jpg-face02942.jpg         0.0\n",
       "29  face01537.jpg-face00187.jpg         0.0\n",
       "30  face03609.jpg-face05219.jpg         0.0\n",
       "31  face04820.jpg-face04526.jpg         0.0\n",
       "32  face05963.jpg-face00176.jpg         1.0\n",
       "33  face04372.jpg-face03101.jpg         0.0\n",
       "34  face01496.jpg-face04980.jpg         0.0\n",
       "35  face04215.jpg-face01123.jpg         0.0\n",
       "36  face02624.jpg-face05000.jpg         0.0\n",
       "37  face04434.jpg-face03376.jpg         1.0\n",
       "38  face03417.jpg-face03461.jpg         0.0\n",
       "39  face03142.jpg-face00593.jpg         0.0\n",
       "40  face00094.jpg-face04094.jpg         0.0\n",
       "41  face05700.jpg-face03910.jpg         1.0\n",
       "42  face03620.jpg-face03203.jpg         0.0\n",
       "43  face05074.jpg-face03806.jpg         0.0\n",
       "44  face03836.jpg-face05917.jpg         0.0\n",
       "45  face04495.jpg-face02846.jpg         1.0\n",
       "46  face01690.jpg-face01033.jpg         0.0\n",
       "47  face01766.jpg-face06057.jpg         1.0\n",
       "48  face04896.jpg-face01845.jpg         1.0\n",
       "49  face05468.jpg-face04688.jpg         1.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.getcwd() + '/input/sample_submission.csv')\n",
    "predictions=[]\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        img0, img1 = data\n",
    "        img0, img1 = img0.cuda(), img1.cuda()\n",
    "        outputs = net(img0,img1)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions = np.concatenate((predictions,predicted.cpu().numpy()),0)\n",
    "        \n",
    "test_df['is_related'] = predictions\n",
    "test_df.to_csv(\"submission.csv\", index=False)\n",
    "test_df.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
